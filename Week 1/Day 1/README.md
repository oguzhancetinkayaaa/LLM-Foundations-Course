# Creating and Training a Encoder-Decoder Style Model (from Attention is All You Need) From Scratch

In the provided notebook, we'll be working through an example of how we can create, and then train, the original Transformer from the [Attention is All You Need](https://arxiv.org/pdf/1706.03762.pdf) paper

You can also find the Colab link to the main assignment [here](https://colab.research.google.com/drive/1zaYE1ps0EHrznWWSAE_mxW1-00GhiTHs?usp=sharing)!

And the BEASTMODE assignment [here](https://colab.research.google.com/drive/1viPrj3M4UXYGEZJwxN4lvJJX-_W6ntdt?usp=sharing)

### How AIM Does Assignments

Throughout our time together - we'll be providing a number of assignments. Each assignment will be split into two broad categories:

1. Base Assignment - a more conceptual and theory based assignment focused on locking in specific key concepts and learnings.
2. BEASTMODE Assignment - a more programming focused assignment focused on core code-concepts used in transformers.

Each assignment will have a few of the following categories of exercises:

1. ‚ùìQuestions - these will be questions that you will be expected to gather the answer to!
2. üèóÔ∏è Activities - these will be work or coding activities meant to reinforce specific concepts or theory components.
3. BEASTMODE Specific: üöß Build Exercises - these will be coding challenges!

You are expected to complete all of the activities in your selected notebook!

## Build üèóÔ∏è

### Build the Model

We wll build the major components of an encoder/decoder style transformer network from scratch using PyTorch. 


### Train the Model

We will train our new network on a toy dataset to showcase how the training loop works and how we pass data through our network.

### Create A Loom Video Walkthrough 

Record a 5 minute loom video walkthrough of the notebook!

## Ship üö¢

Ship a completed notebook to us!

Provide a URL to your loom video walkthrough

## Share üöÄ

Share about your experience in a LinkedIn post, or in the Discord!

* Share 3 lessons learned 
* Share 3 lessons not yet learned
